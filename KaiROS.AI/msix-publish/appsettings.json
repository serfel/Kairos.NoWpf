{
    "AppSettings": {
        "ModelsDirectory": "Models",
        "DefaultBackend": "Auto"
    },
    "LLMModels": [
        {
            "Name": "Qwen2.5-0.5B-Instruct-Q4_K_M.gguf",
            "DisplayName": "Qwen 2.5 0.5B",
            "Description": "Alibaba\u0027s ultra-compact instruction model. Extremely fast for basic tasks.",
            "SizeText": "0.4 GB",
            "SizeBytes": 429916160,
            "DownloadUrl": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF/resolve/main/qwen2.5-0.5b-instruct-q4_k_m.gguf",
            "Capabilities": "Conversation • Ultra Fast • Compact",
            "MinRam": "1 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "All"
        },
        {
            "Name": "Qwen2.5-1.5B-Instruct-Q4_K_M.gguf",
            "DisplayName": "Qwen 2.5 1.5B",
            "Description": "Alibaba\u0027s compact instruction model with excellent multilingual support.",
            "SizeText": "1.0 GB",
            "SizeBytes": 1073741824,
            "DownloadUrl": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf",
            "Capabilities": "Conversation • Multilingual • Efficient",
            "MinRam": "3 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "All"
        },
        {
            "Name": "Qwen2.5-14B-Instruct-Q4_K_M.gguf",
            "DisplayName": "Qwen 2.5 14B",
            "Description": "Alibaba\u0027s large model with exceptional reasoning and multilingual capabilities.",
            "SizeText": "9.0 GB",
            "SizeBytes": 9663676416,
            "DownloadUrl": "https://huggingface.co/bartowski/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-Q4_K_M.gguf",
            "Capabilities": "Advanced Reasoning • Coding • Multilingual • Analysis",
            "MinRam": "16 GB",
            "Category": "large",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "GPU-Recommended"
        },
        {
            "Name": "Qwen2.5-3B-Instruct-Q4_K_M.gguf",
            "DisplayName": "Qwen 2.5 3B",
            "Description": "Alibaba\u0027s efficient 3B model with strong coding and reasoning capabilities.",
            "SizeText": "2.0 GB",
            "SizeBytes": 2147483648,
            "DownloadUrl": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF/resolve/main/qwen2.5-3b-instruct-q4_k_m.gguf",
            "Capabilities": "Conversation • Coding • Reasoning",
            "MinRam": "4 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "All"
        },
        {
            "Name": "Qwen2.5-7B-Instruct-Q4_K_M.gguf",
            "DisplayName": "Qwen 2.5 7B",
            "Description": "Alibaba\u0027s capable 7B model with excellent multilingual and coding abilities.",
            "SizeText": "4.5 GB",
            "SizeBytes": 4831838208,
            "DownloadUrl": "https://huggingface.co/bartowski/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-Q4_K_M.gguf",
            "Capabilities": "Conversation • Coding • Multilingual • Analysis",
            "MinRam": "8 GB",
            "Category": "medium",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "All"
        },
        {
            "Name": "Qwen2.5-Coder-0.5B-Instruct-Q8_0.gguf",
            "DisplayName": "Qwen 2.5 Coder 0.5B",
            "Description": "Alibaba\u0027s tiny coding assistant. Perfect for code completion on CPU.",
            "SizeText": "0.5 GB",
            "SizeBytes": 536870912,
            "DownloadUrl": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF/resolve/main/qwen2.5-coder-0.5b-instruct-q8_0.gguf",
            "Capabilities": "Coding • Fast • CPU Optimized",
            "MinRam": "1 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "CPU-Only"
        },
        {
            "Name": "Qwen3-0.6B-Q4_K_M.gguf",
            "DisplayName": "Qwen 3 0.6B",
            "Description": "Latest Qwen 3 series ultra-small model with improved reasoning capabilities.",
            "SizeText": "0.5 GB",
            "SizeBytes": 536870912,
            "DownloadUrl": "https://huggingface.co/bartowski/Qwen_Qwen3-0.6B-GGUF/resolve/main/Qwen_Qwen3-0.6B-Q4_K_M.gguf",
            "Capabilities": "Conversation • Reasoning • Fast",
            "MinRam": "2 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "All"
        },
        {
            "Name": "Qwen3-1.7B-Q4_K_M.gguf",
            "DisplayName": "Qwen 3 1.7B",
            "Description": "Latest Qwen 3 small model with hybrid thinking capabilities.",
            "SizeText": "1.2 GB",
            "SizeBytes": 1288490188,
            "DownloadUrl": "https://huggingface.co/bartowski/Qwen_Qwen3-1.7B-GGUF/resolve/main/Qwen_Qwen3-1.7B-Q4_K_M.gguf",
            "Capabilities": "Conversation • Reasoning • Thinking",
            "MinRam": "3 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "All"
        },
        {
            "Name": "Qwen3-4B-Q4_K_M.gguf",
            "DisplayName": "Qwen 3 4B",
            "Description": "Latest Qwen 3 with hybrid thinking mode for enhanced reasoning.",
            "SizeText": "2.5 GB",
            "SizeBytes": 2684354560,
            "DownloadUrl": "https://huggingface.co/bartowski/Qwen_Qwen3-4B-GGUF/resolve/main/Qwen_Qwen3-4B-Q4_K_M.gguf",
            "Capabilities": "Conversation • Reasoning • Thinking Mode",
            "MinRam": "6 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "All"
        },
        {
            "Name": "Qwen3-8B-Q4_K_M.gguf",
            "DisplayName": "Qwen 3 8B",
            "Description": "Latest Qwen 3 8B with advanced hybrid thinking for complex reasoning tasks.",
            "SizeText": "5.0 GB",
            "SizeBytes": 5368709120,
            "DownloadUrl": "https://huggingface.co/bartowski/Qwen_Qwen3-8B-GGUF/resolve/main/Qwen_Qwen3-8B-Q4_K_M.gguf",
            "Capabilities": "Advanced Reasoning • Thinking • Coding • Analysis",
            "MinRam": "10 GB",
            "Category": "medium",
            "IsRecommended": false,
            "Organization": "Alibaba",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Qwen_logo.svg/250px-Qwen_logo.svg.png",
            "Family": "Qwen",
            "Variant": "All"
        },
        {
            "Name": "gemma-2-9b-it-Q4_K_M.gguf",
            "DisplayName": "Gemma 2 9B Instruct",
            "Description": "Google\u0027s high-quality 9B model with excellent performance. Great for demanding tasks requiring deep understanding.",
            "SizeText": "5.8 GB",
            "SizeBytes": 6184752128,
            "DownloadUrl": "https://huggingface.co/bartowski/gemma-2-9b-it-GGUF/resolve/main/gemma-2-9b-it-Q4_K_M.gguf",
            "Capabilities": "Premium Quality • Advanced Reasoning • Coding • Creative",
            "MinRam": "12 GB",
            "Category": "medium",
            "IsRecommended": false,
            "Organization": "Google",
            "OrgLogoUrl": "https://www.google.com/images/branding/googleg/1x/googleg_standard_color_128dp.png",
            "Family": "Gemma",
            "Variant": "All"
        },
        {
            "Name": "gemma-3-12b-it-Q4_K_M.gguf",
            "DisplayName": "Gemma 3 12B",
            "Description": "Google\u0027s largest openly available Gemma 3 model with outstanding performance.",
            "SizeText": "7.5 GB",
            "SizeBytes": 8053063680,
            "DownloadUrl": "https://huggingface.co/bartowski/google_gemma-3-12b-it-GGUF/resolve/main/google_gemma-3-12b-it-Q4_K_M.gguf",
            "Capabilities": "Premium Quality • Advanced Reasoning • Creative • Analysis",
            "MinRam": "16 GB",
            "Category": "large",
            "IsRecommended": false,
            "Organization": "Google",
            "OrgLogoUrl": "https://www.google.com/images/branding/googleg/1x/googleg_standard_color_128dp.png",
            "Family": "Gemma",
            "Variant": "GPU-Recommended"
        },
        {
            "Name": "gemma-3-1b-it-Q4_K_M.gguf",
            "DisplayName": "Gemma 3 1B",
            "Description": "Google\u0027s efficient small model with impressive quality for its size. Great for mobile and edge devices.",
            "SizeText": "0.7 GB",
            "SizeBytes": 751619072,
            "DownloadUrl": "https://huggingface.co/bartowski/google_gemma-3-1b-it-GGUF/resolve/main/google_gemma-3-1b-it-Q4_K_M.gguf",
            "Capabilities": "Conversation • Fast • Efficient",
            "MinRam": "2 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Google",
            "OrgLogoUrl": "https://www.google.com/images/branding/googleg/1x/googleg_standard_color_128dp.png",
            "Family": "Gemma",
            "Variant": "All"
        },
        {
            "Name": "google_gemma-3-270m-it-Q4_K_M.gguf",
            "DisplayName": "Gemma 3 270M",
            "Description": "Google\u0027s ultra-lightweight model. Perfect for quick testing and extremely low-resource devices.",
            "SizeText": "0.2 GB",
            "SizeBytes": 214958080,
            "DownloadUrl": "https://huggingface.co/bartowski/google_gemma-3-270m-it-GGUF/resolve/main/google_gemma-3-270m-it-Q4_K_M.gguf",
            "Capabilities": "Conversation • Ultra Fast • Lightweight",
            "MinRam": "1 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Google",
            "OrgLogoUrl": "https://www.google.com/images/branding/googleg/1x/googleg_standard_color_128dp.png",
            "Family": "Gemma",
            "Variant": "All"
        },
        {
            "Name": "gemma-3-27b-it-Q4_K_M.gguf",
            "DisplayName": "Gemma 3 27B",
            "Description": "Google\u0027s flagship Gemma 3 model with exceptional quality and capabilities.",
            "SizeText": "16 GB",
            "SizeBytes": 17179869184,
            "DownloadUrl": "https://huggingface.co/bartowski/google_gemma-3-27b-it-GGUF/resolve/main/google_gemma-3-27b-it-Q4_K_M.gguf",
            "Capabilities": "Premium Quality • Advanced Reasoning • Creative • Vision",
            "MinRam": "32 GB",
            "Category": "xlarge",
            "IsRecommended": false,
            "Organization": "Google",
            "OrgLogoUrl": "https://www.google.com/images/branding/googleg/1x/googleg_standard_color_128dp.png",
            "Family": "Gemma",
            "Variant": "GPU-Recommended"
        },
        {
            "Name": "gemma-3-4b-it-Q4_K_M.gguf",
            "DisplayName": "Gemma 3 4B",
            "Description": "Google\u0027s balanced 4B model with excellent reasoning and instruction following.",
            "SizeText": "2.5 GB",
            "SizeBytes": 2684354560,
            "DownloadUrl": "https://huggingface.co/bartowski/google_gemma-3-4b-it-GGUF/resolve/main/google_gemma-3-4b-it-Q4_K_M.gguf",
            "Capabilities": "Conversation • Reasoning • Balanced",
            "MinRam": "6 GB",
            "Category": "small",
            "IsRecommended": true,
            "Organization": "Google",
            "OrgLogoUrl": "https://www.google.com/images/branding/googleg/1x/googleg_standard_color_128dp.png",
            "Family": "Gemma",
            "Variant": "All"
        },
        {
            "Name": "SmolLM2-1.7B-Instruct-Q4_K_M.gguf",
            "DisplayName": "SmolLM2 1.7B",
            "Description": "Hugging Face\u0027s flagship small model. Great balance of capability and efficiency.",
            "SizeText": "1.0 GB",
            "SizeBytes": 1073741824,
            "DownloadUrl": "https://huggingface.co/bartowski/SmolLM2-1.7B-Instruct-GGUF/resolve/main/SmolLM2-1.7B-Instruct-Q4_K_M.gguf",
            "Capabilities": "Conversation • Reasoning • CPU Optimized",
            "MinRam": "2 GB",
            "Category": "small",
            "IsRecommended": true,
            "Organization": "HuggingFace",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/25720743",
            "Family": "SmolLM",
            "Variant": "CPU-Only"
        },
        {
            "Name": "smollm2-135m-instruct-q8_0.gguf",
            "DisplayName": "SmolLM2 135M",
            "Description": "Hugging Face\u0027s tiniest instruction model. Ultra-fast for basic tasks on any CPU.",
            "SizeText": "0.15 GB",
            "SizeBytes": 161061273,
            "DownloadUrl": "https://huggingface.co/bartowski/SmolLM2-135M-Instruct-GGUF/resolve/main/SmolLM2-135M-Instruct-Q8_0.gguf",
            "Capabilities": "Conversation • Ultra Fast • Edge Device",
            "MinRam": "0.5 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "HuggingFace",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/25720743",
            "Family": "SmolLM",
            "Variant": "CPU-Only"
        },
        {
            "Name": "smollm2-360m-instruct-q8_0.gguf",
            "DisplayName": "SmolLM2 360M",
            "Description": "Compact yet capable instruction model. Perfect for resource-constrained environments.",
            "SizeText": "0.38 GB",
            "SizeBytes": 408021600,
            "DownloadUrl": "https://huggingface.co/bartowski/SmolLM2-360M-Instruct-GGUF/resolve/main/SmolLM2-360M-Instruct-Q8_0.gguf",
            "Capabilities": "Conversation • Fast • Efficient",
            "MinRam": "1 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "HuggingFace",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/25720743",
            "Family": "SmolLM",
            "Variant": "CPU-Only"
        },
        {
            "Name": "Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
            "DisplayName": "LLaMA 3.1 8B Instruct",
            "Description": "Meta\u0027s powerful 8B model with strong reasoning and coding abilities. Excellent for complex tasks and detailed responses.",
            "SizeText": "4.6 GB",
            "SizeBytes": 4920739232,
            "DownloadUrl": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
            "Capabilities": "Advanced Reasoning • Coding • Long Context • Detailed",
            "MinRam": "12 GB",
            "Category": "medium",
            "IsRecommended": false,
            "Organization": "Meta",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Meta_Platforms_logo.svg/330px-Meta_Platforms_logo.svg.png",
            "Family": "Llama",
            "Variant": "All"
        },
        {
            "Name": "Llama-3.2-1B-Instruct-Q4_K_M.gguf",
            "DisplayName": "LLaMA 3.2 1B Instruct",
            "Description": "Meta\u0027s smallest LLaMA 3.2 model. Perfect for lightweight deployment and fast responses.",
            "SizeText": "0.8 GB",
            "SizeBytes": 858993459,
            "DownloadUrl": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf",
            "Capabilities": "Conversation • Fast • Multilingual",
            "MinRam": "2 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Meta",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Meta_Platforms_logo.svg/330px-Meta_Platforms_logo.svg.png",
            "Family": "Llama",
            "Variant": "All"
        },
        {
            "Name": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
            "DisplayName": "LLaMA 3.2 3B Instruct",
            "Description": "Meta\u0027s latest small model with excellent quality. Great balance of size and capability for everyday use.",
            "SizeText": "1.9 GB",
            "SizeBytes": 2040109465,
            "DownloadUrl": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
            "Capabilities": "Conversation • Reasoning • Multilingual",
            "MinRam": "4 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Meta",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Meta_Platforms_logo.svg/330px-Meta_Platforms_logo.svg.png",
            "Family": "Llama",
            "Variant": "All"
        },
        {
            "Name": "tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
            "DisplayName": "TinyLlama 1.1B Chat",
            "Description": "Ultra small and very fast chat model. Great for lightweight tasks and quick responses on low-end hardware.",
            "SizeText": "0.8 GB",
            "SizeBytes": 669737984,
            "DownloadUrl": "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
            "Capabilities": "Conversation • Fast • Lightweight",
            "MinRam": "2 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Meta",
            "OrgLogoUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Meta_Platforms_logo.svg/330px-Meta_Platforms_logo.svg.png",
            "Family": "Llama",
            "Variant": "All"
        },
        {
            "Name": "ggml-model-i2_s.gguf",
            "DisplayName": "BitNet b1.58 2B",
            "Description": "Microsoft\u0027s revolutionary 1-bit quantized model. Extremely efficient CPU inference with minimal memory.",
            "SizeText": "0.5 GB",
            "SizeBytes": 536870912,
            "DownloadUrl": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-gguf/resolve/main/ggml-model-i2_s.gguf",
            "Capabilities": "1-Bit • Ultra Efficient • CPU Optimized",
            "MinRam": "2 GB",
            "Category": "small",
            "IsRecommended": true,
            "Organization": "Microsoft",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/6154722",
            "Family": "BitNet",
            "Variant": "CPU-Only"
        },
        {
            "Name": "phi-2.Q4_K_M.gguf",
            "DisplayName": "Phi-2 2.7B",
            "Description": "Compact yet powerful model with strong reasoning abilities. Excellent for coding tasks and technical conversations.",
            "SizeText": "1.6 GB",
            "SizeBytes": 1719664935,
            "DownloadUrl": "https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf",
            "Capabilities": "Coding • Reasoning • Technical • Compact",
            "MinRam": "4 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Microsoft",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/6154722",
            "Family": "Phi",
            "Variant": "All"
        },
        {
            "Name": "Phi-3-mini-4k-instruct-q4.gguf",
            "DisplayName": "Phi-3 Mini 3.8B",
            "Description": "Microsoft\u0027s excellent small model with impressive capabilities for its size. Great for general conversations, reasoning, and basic coding.",
            "SizeText": "2.2 GB",
            "SizeBytes": 2362232012,
            "DownloadUrl": "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf",
            "Capabilities": "Conversation • Reasoning • Coding • Fast",
            "MinRam": "4 GB",
            "Category": "small",
            "IsRecommended": true,
            "Organization": "Microsoft",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/6154722",
            "Family": "Phi",
            "Variant": "All"
        },
        {
            "Name": "mistral-7b-instruct-v0.2.Q4_K_M.gguf",
            "DisplayName": "Mistral 7B Instruct v0.2",
            "Description": "Popular and highly capable 7B model with excellent instruction following. Great for complex conversations and tasks.",
            "SizeText": "4.4 GB",
            "SizeBytes": 4692829210,
            "DownloadUrl": "https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf",
            "Capabilities": "Advanced Conversation • Coding • Analysis • Creative",
            "MinRam": "8 GB",
            "Category": "medium",
            "IsRecommended": true,
            "Organization": "MistralAI",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/132372032",
            "Family": "Mistral",
            "Variant": "All"
        },
        {
            "Name": "Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf",
            "DisplayName": "Mistral Small 24B",
            "Description": "MistralAI\u0027s powerful small series flagship. Excellent for complex tasks requiring deep understanding.",
            "SizeText": "14 GB",
            "SizeBytes": 15032385536,
            "DownloadUrl": "https://huggingface.co/bartowski/Mistral-Small-24B-Instruct-2501-GGUF/resolve/main/Mistral-Small-24B-Instruct-2501-Q4_K_M.gguf",
            "Capabilities": "Premium Quality • Advanced Reasoning • Coding • Long Context",
            "MinRam": "24 GB",
            "Category": "large",
            "IsRecommended": false,
            "Organization": "MistralAI",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/132372032",
            "Family": "Mistral",
            "Variant": "GPU-Recommended"
        },
        {
            "Name": "gpt-oss-20b-Q4_K_M.gguf",
            "DisplayName": "GPT-oss 20B ⚠️ Experimental",
            "Description": "[EXPERIMENTAL] OpenAI's first open-weight model with MoE architecture. May not load due to MoE support limitations in llama.cpp.",
            "SizeText": "12 GB",
            "SizeBytes": 12884901888,
            "DownloadUrl": "https://huggingface.co/bartowski/openai_gpt-oss-20b-GGUF/resolve/main/openai_gpt-oss-20b-Q4_K_M.gguf",
            "Capabilities": "Advanced Reasoning • Thinking • Coding • MoE",
            "MinRam": "16 GB",
            "Category": "large",
            "IsRecommended": false,
            "Organization": "OpenAI",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/14957082",
            "Family": "GPT",
            "Variant": "GPU-Recommended"
        },
        {
            "Name": "rwkv7-0.1B-g1-Q8_0.gguf",
            "DisplayName": "RWKV-7 0.1B",
            "Description": "Ultra-tiny RNN model with linear complexity. Fastest inference possible.",
            "SizeText": "0.1 GB",
            "SizeBytes": 107374182,
            "DownloadUrl": "https://huggingface.co/latestissue/rwkv7-g1-0.1b-gguf/resolve/main/rwkv7-g1-0.1b-Q8_0.gguf",
            "Capabilities": "Conversation • Linear Time • Constant Memory",
            "MinRam": "0.5 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "RWKV",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/125334954",
            "Family": "RWKV",
            "Variant": "CPU-Only"
        },
        {
            "Name": "stablelm-zephyr-3b.Q4_K_M.gguf",
            "DisplayName": "StableLM Zephyr 3B",
            "Description": "Stability AI\u0027s efficient instruction model. Excellent for chat and general tasks.",
            "SizeText": "1.8 GB",
            "SizeBytes": 1932735283,
            "DownloadUrl": "https://huggingface.co/TheBloke/stablelm-zephyr-3b-GGUF/resolve/main/stablelm-zephyr-3b.Q4_K_M.gguf",
            "Capabilities": "Conversation • Instruction Following • Efficient",
            "MinRam": "4 GB",
            "Category": "small",
            "IsRecommended": false,
            "Organization": "Stability AI",
            "OrgLogoUrl": "https://avatars.githubusercontent.com/u/100950301",
            "Family": "StableLM",
            "Variant": "CPU-Only"
        }
    ]
}